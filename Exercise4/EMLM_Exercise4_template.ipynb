{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a597809e",
   "metadata": {},
   "source": [
    "# Exercise 4 | TKO_7092 Evaluation of Machine Learning Methods\n",
    "---\n",
    "\n",
    "Anton Teerioja<br>\n",
    "2214231<br>\n",
    "asteer@utu.fi<br>\n",
    "\n",
    "---\n",
    "\n",
    "The deadline for returning this exercise is **25.2.2026**.\n",
    "\n",
    "If you have any questions about this exercise, please contact Riikka Numminen (rimanu@utu.fi) in good time before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7c871",
   "metadata": {},
   "source": [
    "## Nested cross-validation for feature selection\n",
    "In this exercise, the task is to use leave-one-out cross-validation for model selection to understand the effect of the winner's curse. \n",
    "This is demonstrated by using greedy forward selection and a random binary data set.\n",
    "The data set is a balanced sample of size 60 (i.e. 30 positives and 30 negatives) with a hundred features. The data are i.i.d., and every feature follows a Bernoulli distribution with $p=0.5$. Thus, there is no signal in the data. \n",
    "\n",
    "The model to be used is 1-nearest neighbour with 10 features, and the greedy forward selection is used to select the best 10 features among all the features.\n",
    "Leave-one-out cross-validation is used for performance evaluation, and the prediction performance is measured as accuracy. \n",
    "\n",
    "### Greedy forward feature selection\n",
    "Greedy forward feature selection is an iterative feature selection process, where the features are selected one by one, avoiding a need to iterate through every possible combination of features. The features are selected as follows:\n",
    "- First, every feature is tested solely and the best is selected.\n",
    "- Then the selected feature is tested together with any other remaining feature and the best such a set of two features is selected.\n",
    "- Then that set of the selected two features is tested together with any other remaining feature and the best set of three features is selected.\n",
    "- The process is then continued accordingly until the desired amount of features is selected.\n",
    "\n",
    "### Implement the following tasks to complete this exercise:\n",
    "1. Use leave-one-out cross-validation to select the best 10 features. Report the optimal set of features and the corresponding accuracy.\n",
    "2. Use nested leave-one-out cross-validation (leave-one-out on both layers of cross-validation) to obtain an estimate of the prediction accuracy on unseen data, when the final hypotheses are obtained according to the procedure in the first step.\n",
    "3. Explain the difference in the obtained accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c9b00",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df6b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, import all the libraries that you will use in this notebook. For example:\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15d9b4",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "The labels are saved in a file *y_generated.csv*, and the features in file *X_generated.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c06938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 100) (60, 1)\n"
     ]
    }
   ],
   "source": [
    "# Read the data files. Verify that the data dimensions are as expected.\n",
    "X = pd.read_csv('X_generated.csv', header=None)\n",
    "y = pd.read_csv('y_generated.csv', header=None)\n",
    "\n",
    "#Ensure that both groups have 60 instances and that there are 100 features\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602dda34",
   "metadata": {},
   "source": [
    "### Leave-one-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe5adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [ 0  1  6 24 35 55 64 65 73 94]\n",
      "Accuracy: 0.7666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Write your implementation for the first part of the exercise here.\n",
    "knn = KNeighborsClassifier(n_neighbors=1, n_jobs=-1)\n",
    "\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=10, direction='forward', cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "sfs.fit(X, y.values.ravel())\n",
    "\n",
    "# Select the features\n",
    "selected_features_1 = sfs.get_support(indices=True)\n",
    "X_selected = X.iloc[:, selected_features_1]\n",
    "\n",
    "# Evaluate accuracy without LOOCV cross-validation\n",
    "accuracy_1 = cross_val_score(knn, X_selected, y.values.ravel(), scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print(f\"Selected features: {selected_features_1}\")\n",
    "print(f\"Accuracy: {accuracy_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7e3de",
   "metadata": {},
   "source": [
    "### Nested leave-one-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29aa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [ 0  1  6 24 35 55 64 65 73 94]\n",
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write your implementation for the second part of the exercise here.\n",
    "knn = KNeighborsClassifier(n_neighbors=1, n_jobs=-1)\n",
    "\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=10, direction='forward', cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "sfs.fit(X, y.values.ravel())\n",
    "\n",
    "# Select the features\n",
    "selected_features_2 = sfs.get_support(indices=True)\n",
    "X_selected = X.iloc[:, selected_features_2]\n",
    "\n",
    "# Evaluate accuracy using LOOCV cross-validation\n",
    "accuracy_2 = cross_val_score(knn, X_selected, y.values.ravel(), cv=LeaveOneOut(), scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print(f\"Selected features: {selected_features_2}\")\n",
    "print(f\"Accuracy: {accuracy_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25eebac",
   "metadata": {},
   "source": [
    "### Analyse the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5fc946",
   "metadata": {},
   "source": [
    "Why are the results as they are? Why is the nested cross-validation needed?\n",
    "\n",
    "Both methods selected the same features with the first method producing a worse accuracy score than the second method.\n",
    "\n",
    "In the first method the LOOCV cross-validation was used to select the 10 best features. In the second method the LOOCV cross-validation was also used in calculating the accuracy of the greedy forward feature selection. Because the greedy algorithm doesn't always produce the highest accuracy result, the second layer of cross-validation can help with finding the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f5e1c",
   "metadata": {},
   "source": [
    "### AI usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b28f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case AI was used when solving the exercise, please explain how and in which parts it was used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data-Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
